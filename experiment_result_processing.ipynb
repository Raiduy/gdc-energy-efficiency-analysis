{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import eesr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creates a dataframe with the results of the experiments based on the parameters.\n",
    "def create_dataframe(path_ex, file_name, dcs = '', tpp = ''):\n",
    "    select_dcs = \"dcs_\" + dcs\n",
    "    select_tpp = \"tpp_\" + tpp\n",
    "    df = pd.DataFrame()\n",
    "    for folder in next(os.walk(path_ex))[1]:\n",
    "        if (select_dcs in folder) & (select_tpp in folder):\n",
    "            file_path = os.path.join(path_ex, folder, file_name)\n",
    "            if '.tsv' in file_name:\n",
    "              data = pd.read_csv(file_path, delimiter='\\t')\n",
    "            else:\n",
    "              data = pd.read_csv(file_path, delimiter=',')\n",
    "            data['trace_name'] = folder\n",
    "            df = pd.concat([df, data])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Creates a dataframe with the environment stats of the specified file.\n",
    "def create_env_dataframe(path_ex, trace_name):\n",
    "    file_name = 'environment.csv'\n",
    "    df = pd.DataFrame()\n",
    "    for folder in next(os.walk(path_ex))[1]:\n",
    "        if (trace_name in folder):\n",
    "            file_path = os.path.join(path_ex, folder, file_name)\n",
    "            data = pd.read_csv(file_path)\n",
    "            data['trace_name'] = folder\n",
    "            df = pd.concat([df, data])\n",
    "    return df\n",
    "\n",
    "# Splits the environment dataframe into a dataframe for each environment and writes it to a csv file.\n",
    "# def split_env_dataframe(df, path_ex):\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Experiment paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_ex1 = '../EX_1/'\n",
    "path_ex2 = '../EX_2/'\n",
    "\n",
    "colors = ['lightcoral', 'steelblue', 'yellowgreen']\n",
    "colors2 = ['#F05039', '#E57A77', '#1F449C', '#3D65A5', '#7CA1CC', '#A8B6CC']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datacentre dependent dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dc1_df = create_dataframe(path_ex=path_ex1, file_name = 'stats.tsv', dcs='1', tpp='')\n",
    "stats_dc2_df = create_dataframe(path_ex=path_ex1, file_name = 'stats.tsv', dcs='2', tpp='')\n",
    "\n",
    "summary_dc1_df = create_dataframe(path_ex=path_ex1, file_name = 'summary.tsv', dcs='1', tpp='')\n",
    "summary_dc2_df = create_dataframe(path_ex=path_ex1, file_name = 'summary.tsv', dcs='2', tpp='')\n",
    "\n",
    "tasks_dc1_df = create_dataframe(path_ex=path_ex1, file_name = 'tasks.tsv', dcs='1', tpp='')\n",
    "tasks_dc2_df = create_dataframe(path_ex=path_ex1, file_name = 'tasks.tsv', dcs='2', tpp='')\n",
    "\n",
    "workflows_dc1_df = create_dataframe(path_ex=path_ex1, file_name = 'workflows.tsv', dcs='1', tpp='')\n",
    "workflows_dc2_df = create_dataframe(path_ex=path_ex1, file_name = 'workflows.tsv', dcs='2', tpp='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dc1_df[summary_dc1_df['metric'] == 'Workflow Normalized Schedule Length']['mean'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dc1_df[summary_dc1_df['metric'] == 'Workflow Schedule Length']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fastest Machine Placement variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stats_dc1_fmp_df = create_dataframe(path_ex=path_ex1, file_name = 'stats.tsv', dcs='1', tpp='fastest_machine')\n",
    "stats_dc2_fmp_df = create_dataframe(path_ex=path_ex1, file_name = 'stats.tsv', dcs='2', tpp='fastest_machine')\n",
    "\n",
    "summary_dc1_fmp_df = create_dataframe(path_ex=path_ex1, file_name = 'summary.tsv', dcs='1', tpp='fastest_machine')\n",
    "summary_dc2_fmp_df = create_dataframe(path_ex=path_ex1, file_name = 'summary.tsv', dcs='2', tpp='fastest_machine')\n",
    "\n",
    "tasks_dc1_fmp_df = create_dataframe(path_ex=path_ex1, file_name = 'tasks.tsv', dcs='1', tpp='fastest_machine')\n",
    "tasks_dc2_fmp_df = create_dataframe(path_ex=path_ex1, file_name = 'tasks.tsv', dcs='2', tpp='fastest_machine')\n",
    "\n",
    "workflows_dc1_fmp_df = create_dataframe(path_ex=path_ex1, file_name = 'workflows.tsv', dcs='1', tpp='fastest_machine')\n",
    "workflows_dc2_fmp_df = create_dataframe(path_ex=path_ex1, file_name = 'workflows.tsv', dcs='2', tpp='fastest_machine')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look Ahead Placement variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats_dc1_lah_df = create_dataframe(path_ex=path_ex1, file_name = 'stats.tsv', dcs='1', tpp='look_ahead')\n",
    "stats_dc2_lah_df = create_dataframe(path_ex=path_ex1, file_name = 'stats.tsv', dcs='2', tpp='look_ahead')\n",
    "\n",
    "summary_dc1_lah_df = create_dataframe(path_ex=path_ex1, file_name = 'summary.tsv', dcs='1', tpp='look_ahead')\n",
    "summary_dc2_lah_df = create_dataframe(path_ex=path_ex1, file_name = 'summary.tsv', dcs='2', tpp='look_ahead')\n",
    "\n",
    "tasks_dc1_lah_df = create_dataframe(path_ex=path_ex1, file_name = 'tasks.tsv', dcs='1', tpp='look_ahead')\n",
    "tasks_dc2_lah_df = create_dataframe(path_ex=path_ex1, file_name = 'tasks.tsv', dcs='2', tpp='look_ahead')\n",
    "\n",
    "workflows_dc1_lah_df = create_dataframe(path_ex=path_ex1, file_name = 'workflows.tsv', dcs='1', tpp='look_ahead')\n",
    "workflows_dc2_lah_df = create_dataframe(path_ex=path_ex1, file_name = 'workflows.tsv', dcs='2', tpp='look_ahead')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dc1_df[stats_dc1_df['trace_name'] == 'askalon-new_ee68_parquet_tpp_look_ahead_dcs_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dc1_df[stats_dc1_df['AvgResourceUsage'] >= 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dc1_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dc1_df.boxplot(column=['AvgResourceUsage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dc2_df[stats_dc2_df['AvgResourceUsage'] >= 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_performance_dc1 = create_dataframe(path_ex1, 'tasks.tsv', '1', 'fastest_machine')\n",
    "lookahead_performance_dc1 = create_dataframe(path_ex1, 'tasks.tsv', '1', 'look_ahead')\n",
    "\n",
    "lookahead_performance_dc1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tasks_dc1_fmp_df.groupby('trace_name').sum()['energy.consumed'].describe())\n",
    "tasks_dc1_lah_df.groupby('trace_name').sum()['energy.consumed'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl = tasks_dc1_fmp_df.groupby('trace_name').sum()['energy.consumed'].sum()/1000\n",
    "nl = tasks_dc1_lah_df.groupby('trace_name').sum()['energy.consumed'].sum()/1000\n",
    "\n",
    "difference_percentage = (nl - bl) / bl * 100\n",
    "print(difference_percentage, '%')\n",
    "print('Baseline: ', bl)\n",
    "print('Lookahead: ', nl)\n",
    "\n",
    "\n",
    "bar_height = 0.5\n",
    "fig, ax = plt.subplots(figsize=(7, 1.5))\n",
    "ax.barh('Fastest Machine + DVFS', bl, color=colors[0], height=bar_height)\n",
    "ax.barh('Lookahead + DVFS', nl, color=colors[1], height=bar_height)\n",
    "ax.set_title('Total energy consumption for one datacentre')\n",
    "ax.set_xlabel('Energy consumption [MWh]')\n",
    "ax.set_ylabel('Method')\n",
    "ax.margins(x=0.1, y=0.2)\n",
    "ax.text(nl, 1, str(round(difference_percentage, 2))+'%', color='black', fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "''' \n",
    "TODO:\n",
    "increase text size (figure text at least as big as text in caption)\n",
    "axes labels size of caption text\n",
    "increase method and Energy consumption text size (125% of lah and baseline text size)\n",
    "Task energy consumption for one datacentre (150% or more of caption text size, but this will be the actual caption in the paper)\n",
    "\n",
    "Decrease the size of the bars (vertically) (2x size of text in method type)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow_delays[ttp][dvfs_enabled][domain].extend(workflow_df['time.complete'] - workflow_df['time.earliest.complete'])\n",
    "workflows_dc1_fmp_df['workflow_delays'] = workflows_dc1_fmp_df['time.complete'] - workflows_dc1_fmp_df['time.earliest.complete']\n",
    "workflows_dc1_lah_df['workflow_delays'] = workflows_dc1_lah_df['time.complete'] - workflows_dc1_lah_df['time.earliest.complete']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cumulative workflow delays\n",
    "total_delay_fmp = workflows_dc1_fmp_df['workflow_delays'].sum()/1000/60/60\n",
    "total_delay_lah = workflows_dc1_lah_df['workflow_delays'].sum()/1000/60/60\n",
    "\n",
    "# calculate the percentage of delay\n",
    "delay_percentage = (total_delay_lah - total_delay_fmp) / total_delay_fmp * 100\n",
    "print(delay_percentage, '%')\n",
    "print('Baseline: ', total_delay_fmp)\n",
    "print('Lookahead: ', total_delay_lah)\n",
    "\n",
    "\n",
    "bar_height = 0.5\n",
    "fig, ax = plt.subplots(figsize=(7, 1.5))\n",
    "ax.barh('Fastest Machine + DVFS', total_delay_fmp, color=colors[0], height=bar_height)\n",
    "ax.barh('Lookahead + DVFS', total_delay_lah, color=colors[1], height=bar_height)\n",
    "ax.set_title('Total workflow delay for one datacentre')\n",
    "ax.set_xlabel('Time [h]')\n",
    "ax.set_ylabel('Method')\n",
    "ax.margins(x=0.14, y=0.2)\n",
    "ax.text(total_delay_lah, 1, '+'+str(round(delay_percentage, 2))+'%', color='black', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "Also show workflow Slowdown (box and whisker plot + violin plot) (workflow normalized schedule length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process**:\n",
    "1. Select from the 1 DC runs:\n",
    "    * a) one representative trace for each target utilization in increments of 10%\n",
    "    * b) one trace with average, shortest and longest running times\n",
    "2. Compute utilization graphs for \n",
    "    * a) fastest machine placement (fmp)\n",
    "    * b) lookahead (lah) placement\n",
    "    * c) compare fmp in 1 DC vs 2 DC\n",
    "    * d) compare lah in 1 DC vs 2 DC\n",
    "3. Calculate total energy consumption (including idle consumption) for each trace\n",
    "4. Select the corresponding traces from the 2 DC runs\n",
    "5. Run the DCs in different country configurations and show the results from EESR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats_dc1_fmp_df = create_dataframe(path_ex=path_ex1, file_name = 'stats.tsv', dcs='1', tpp='fastest_machine')\n",
    "utilization_candidates_fmp = stats_dc1_fmp_df.sort_values(by=['AvgResourceUsage'], ascending=False)[['trace_name', 'AvgResourceUsage']]\n",
    "\n",
    "stats_dc1_lah_df = create_dataframe(path_ex=path_ex1, file_name = 'stats.tsv', dcs='1', tpp='look_ahead')\n",
    "utilization_candidates_lah = stats_dc1_lah_df.sort_values(by=['AvgResourceUsage'], ascending=False)[['trace_name', 'AvgResourceUsage']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_stats = stats_dc1_fmp_df['TraceDuration'].describe()\n",
    "\n",
    "max_duration_trace = stats_dc1_fmp_df[stats_dc1_fmp_df['TraceDuration'] == duration_stats['max']].sort_values(by=['AvgResourceUsage'], ascending=False)['trace_name'].values[0]\n",
    "median_high_duration_trace = stats_dc1_fmp_df[stats_dc1_fmp_df['TraceDuration'] <= duration_stats['50%']].sort_values(by=['TraceDuration'], ascending=False)['trace_name'].values[0]\n",
    "median_low_duration_trace = stats_dc1_fmp_df[stats_dc1_fmp_df['TraceDuration'] >= duration_stats['50%']].sort_values(by=['TraceDuration'], ascending=True)['trace_name'].values[0]\n",
    "sorted_df = stats_dc1_fmp_df.sort_values(by=['TraceDuration'], ascending=True)\n",
    "min_duration_trace = sorted_df[sorted_df['TraceDuration'] > 900_000]['trace_name'].head(1).values[0]\n",
    "print(min_duration_trace)\n",
    "duration_candidates_fmp = pd.DataFrame({'trace_name': [max_duration_trace, median_high_duration_trace, median_low_duration_trace, min_duration_trace],\n",
    "                                    'duration': ['max', 'median-high', 'median-low', 'min']})\n",
    "\n",
    "\n",
    "\n",
    "duration_stats = stats_dc1_lah_df['TraceDuration'].describe()\n",
    "\n",
    "max_duration_trace = stats_dc1_lah_df[stats_dc1_lah_df['TraceDuration'] == duration_stats['max']].sort_values(by=['AvgResourceUsage'], ascending=False)['trace_name'].values[0]\n",
    "median_high_duration_trace = stats_dc1_lah_df[stats_dc1_lah_df['TraceDuration'] <= duration_stats['50%']].sort_values(by=['TraceDuration'], ascending=False)['trace_name'].values[0]\n",
    "median_low_duration_trace = stats_dc1_lah_df[stats_dc1_lah_df['TraceDuration'] >= duration_stats['50%']].sort_values(by=['TraceDuration'], ascending=True)['trace_name'].values[0]\n",
    "# min_duration_trace = stats_dc1_lah_df[stats_dc1_lah_df['TraceDuration'] == duration_stats['min']].sort_values(by=['AvgResourceUsage'], ascending=False)['trace_name'].values[0]\n",
    "sorted_df = stats_dc1_lah_df.sort_values(by=['TraceDuration'], ascending=True)\n",
    "min_duration_trace = sorted_df[sorted_df['TraceDuration'] > 1_800_000]['trace_name'].head(1).values[0]\n",
    "print(min_duration_trace)\n",
    "duration_candidates_lah = pd.DataFrame({'trace_name': [max_duration_trace, median_high_duration_trace, median_low_duration_trace, min_duration_trace],\n",
    "                                    'duration': ['max', 'median-high', 'median-low', 'min']})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_machines = 9\n",
    "TDP = 225\n",
    "idleTDP = 100\n",
    "timeframe = 0.25 # 15 minutes\n",
    "\n",
    "def get_energy_consumption(num_machines, timeframe, idleTDP, TDP):\n",
    "    total_TDP = TDP * num_machines   # total TDP of all machines\n",
    "    total_idleTDP = idleTDP * num_machines   # total idle TDP of all machines\n",
    "    theoretical_max = total_TDP * timeframe * 3600   # Total TDP for 15 minutes converted to Joules\n",
    "    theoretical_min = total_idleTDP * timeframe * 3600\n",
    "    theoretical_min_dvfs = theoretical_min * (1 - 0.126) # maximum DVFS reduction\n",
    "    return theoretical_max, theoretical_min, theoretical_min_dvfs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_OF_GRAPHS = 4\n",
    "\n",
    "conversion_factor = 1_000_000\n",
    "conversion_name = 'M'\n",
    "\n",
    "theoretical_max, theoretical_min, theoretical_min_dvfs = get_energy_consumption(num_machines, timeframe, idleTDP, TDP)\n",
    "theoretical_max = theoretical_max / conversion_factor\n",
    "theoretical_min = theoretical_min / conversion_factor\n",
    "theoretical_min_dvfs = theoretical_min_dvfs / conversion_factor\n",
    "\n",
    "top_limit = 2000000\n",
    "top_limit = top_limit / conversion_factor\n",
    "\n",
    "\n",
    "def draw_day_lines(df, ax):\n",
    "    num_lines = int(df['timestamp'].max() // 24) + 1\n",
    "    for i in range(num_lines):\n",
    "        ax.axvline(x=i*24, color = 'black')\n",
    "\n",
    "def plot_energy_consumption(df_fmp, df_lah, theoretical_max, theoretical_min, theoretical_min_dvfs, max_graphs):\n",
    "    graph_counter = 0\n",
    "    for i in range(len(df_fmp)):\n",
    "        if max_graphs > 0:\n",
    "            if graph_counter > max_graphs:\n",
    "                break\n",
    "        \n",
    "        fmp_name = df_fmp.iloc[i]['trace_name']\n",
    "        lah_name = df_lah.iloc[i]['trace_name']\n",
    "\n",
    "        fmp_env = create_env_dataframe(path_ex1, fmp_name)\n",
    "        lah_env = create_env_dataframe(path_ex1, lah_name)\n",
    "        top_limit = 2000000\n",
    "\n",
    "        # convert to kJ\n",
    "        fmp_env['it_power_total'] = fmp_env['it_power_total'] / conversion_factor\n",
    "        lah_env['it_power_total'] = lah_env['it_power_total'] / conversion_factor\n",
    "        top_limit = top_limit / conversion_factor\n",
    "\n",
    "        # convert to hours\n",
    "        fmp_env['timestamp'] = fmp_env['timestamp'] / 1000 / 60 / 60\n",
    "        lah_env['timestamp'] = lah_env['timestamp'] / 1000 / 60 / 60\n",
    "\n",
    "\n",
    "        # plot fmp and lah it power total\n",
    "        if len(fmp_env) > 2:\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "            ax.plot(lah_env['timestamp'], fmp_env['it_power_total'], 'o', ls='-', ms=10, color=colors[0], label='FMP', linewidth=2.5, markevery=0.1)\n",
    "            ax.plot(lah_env['timestamp'], lah_env['it_power_total'], 'v', ls='-', ms=10, color=colors[1], label='LAH', linewidth=2.5, markevery=0.3)\n",
    "\n",
    "            # fill between with blue where fmp is higher than lah and yellow where lah is higher than fmp\n",
    "            plt.fill_between(lah_env['timestamp'], lah_env['it_power_total'], fmp_env['it_power_total'], where=fmp_env['it_power_total'] >= lah_env['it_power_total'],\n",
    "                              facecolor='yellow', alpha=0.3)\n",
    "            plt.fill_between(lah_env['timestamp'], lah_env['it_power_total'], fmp_env['it_power_total'], where=fmp_env['it_power_total'] <= lah_env['it_power_total'], \n",
    "                              facecolor='cyan', alpha=0.3)\n",
    "            \n",
    "            text_x_coord = lah_env['timestamp'].max()\n",
    "            ax.axhline(y=theoretical_max, color='red', linestyle=':', linewidth=2)\n",
    "            ax.text(text_x_coord-0.08*text_x_coord, theoretical_max-0.07, f'Max = {round(theoretical_max, 2)}', color='black', fontweight='bold')\n",
    "\n",
    "            ax.axhline(y=theoretical_min, color='green', linestyle=':', linewidth=2)\n",
    "            ax.text(text_x_coord-0.08*text_x_coord, theoretical_min-0.07, f'Idle = {round(theoretical_min, 2)}', color='black', fontweight='bold')        \n",
    "            \n",
    "            ax.axhline(y=theoretical_min_dvfs, color='blue', linestyle=':', linewidth=2)\n",
    "            ax.text(text_x_coord-0.2*text_x_coord, theoretical_min_dvfs-0.07, f'Idle with DVFS = {round(theoretical_min_dvfs, 2)}', color='black', fontweight='bold')\n",
    "\n",
    "            plt.fill_between(lah_env['timestamp'], 0, theoretical_min_dvfs, facecolor='black', alpha=0.3)\n",
    "            plt.fill_between(lah_env['timestamp'], theoretical_max, top_limit, facecolor='red', alpha=0.6)\n",
    "            \n",
    "            draw_day_lines(lah_env, ax)\n",
    "\n",
    "            ax.grid(True)\n",
    "\n",
    "            ax.set_title('IT power consumption for trace: ' + fmp_name\n",
    "                          + '\\nAverage power consumption: ' + utilization_candidates_fmp.iloc[i]['AvgResourceUsage'].astype(str))\n",
    "            ax.set_xlabel('Time [h]')\n",
    "            ax.set_ylabel(f'Energy [{conversion_name}J]')\n",
    "            \n",
    "            ax.set_ylim(0, top_limit)\n",
    "\n",
    "            ax.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            graph_counter += 1\n",
    "        else:\n",
    "            print('trace too short: ', fmp_name, ' ', len(fmp_env))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilization candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_energy_consumption(utilization_candidates_fmp, utilization_candidates_lah, theoretical_max, theoretical_min, theoretical_min_dvfs, MAX_NUM_OF_GRAPHS)\n",
    "''' \n",
    "for traces that show no movement for a long time, truncate them (specify in the thesis)\n",
    "---\n",
    "add labels to important points (ex: 1.82)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_energy_consumption(duration_candidates_fmp, duration_candidates_lah, theoretical_max, theoretical_min, theoretical_min_dvfs, MAX_NUM_OF_GRAPHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_vs_graphs(candidates, theoretical_max, theoretical_min, max_graphs, placement_policy):\n",
    "    vs_graph_counter = 0\n",
    "    \n",
    "    for i in range(len(candidates)):\n",
    "        if max_graphs > 0:\n",
    "            if vs_graph_counter > max_graphs:\n",
    "                break\n",
    "        dc_1 = candidates.iloc[i]['trace_name']\n",
    "        dc_2 = candidates.iloc[i]['trace_name'][:-1] + '2'\n",
    "        \n",
    "        env_dc_1 = create_env_dataframe(path_ex1, dc_1)\n",
    "        env_dc_2 = create_env_dataframe(path_ex1, dc_2)\n",
    "\n",
    "        env_dc_1['it_power_total'] = env_dc_1['it_power_total'] / conversion_factor\n",
    "        env_dc_2['it_power_total'] = env_dc_2['it_power_total'] / conversion_factor\n",
    "\n",
    "        env_dc_1['timestamp'] = env_dc_1['timestamp'] / 1000 / 60 / 60\n",
    "        env_dc_2['timestamp'] = env_dc_2['timestamp'] / 1000 / 60 / 60\n",
    "\n",
    "        # fmp_env['it_power_total']\n",
    "\n",
    "        # plot fmp and lah it power total\n",
    "        if len(env_dc_1) > 1:\n",
    "            fig, (ax, ax1) = plt.subplots(1, 2, figsize=(17, 5))\n",
    "\n",
    "            # ax.plot(lah_env['timestamp'], lah_env['it_power_total'], 'v', ls='--', ms=6, color=colors[1], label='LAH', linewidth=2, markevery=0.3)\n",
    "\n",
    "            ax.plot(env_dc_1['timestamp'], env_dc_1['it_power_total'], 'o', ls='-', ms=10, color=colors2[0], label=f'{placement_policy} 1 DC', linewidth=2, markevery=0.1)\n",
    "            ax.plot(env_dc_2[env_dc_2['host_id'] == '0-0']['timestamp'], env_dc_2[env_dc_2['host_id'] == '0-0']['it_power_total'], 'v', ls='-', ms=10, color = colors2[2], label=f'{placement_policy} 2 DC, 1', linewidth=2, markevery=0.15)\n",
    "            ax.plot(env_dc_2[env_dc_2['host_id'] == '1-1']['timestamp'], env_dc_2[env_dc_2['host_id'] == '1-1']['it_power_total'], '^', ls='-', ms=10, color = colors2[4], label=f'{placement_policy} 2 DC, 2', linewidth=2, markevery=0.2)\n",
    "\n",
    "            text_x_coord = max(env_dc_2['timestamp'].max(), env_dc_1['timestamp'].max())\n",
    "            ax.axhline(y=theoretical_max, color='red', linestyle=':', linewidth=2)\n",
    "            ax.text(text_x_coord-0.12*text_x_coord, theoretical_max-0.07, f'Max = {round(theoretical_max, 2)}', color='black', fontweight='bold')\n",
    "\n",
    "            ax.axhline(y=theoretical_min, color='green', linestyle=':', linewidth=2)\n",
    "            ax.text(text_x_coord-0.12*text_x_coord, theoretical_min-0.07, f'Idle = {round(theoretical_min, 2)}', color='black', fontweight='bold')        \n",
    "            \n",
    "            # ax.axhline(y=theoretical_min_dvfs, color='blue', linestyle=':', linewidth=2)\n",
    "            # ax.text(text_x_coord-0.27*text_x_coord, theoretical_min_dvfs-0.07, f'Idle with DVFS = {round(theoretical_min_dvfs, 2)}', color='black', fontweight='bold')\n",
    "\n",
    "            if env_dc_1['timestamp'].max() < env_dc_2['timestamp'].max():\n",
    "                ax.fill_between(env_dc_2['timestamp'], 0, theoretical_min, facecolor='black', alpha=0.3)\n",
    "                ax.fill_between(env_dc_2['timestamp'], theoretical_max, top_limit, facecolor='red', alpha=0.6)\n",
    "            else:\n",
    "                ax.fill_between(env_dc_1['timestamp'], 0, theoretical_min, facecolor='black', alpha=0.3)\n",
    "                ax.fill_between(env_dc_1['timestamp'], theoretical_max, top_limit, facecolor='red', alpha=0.6)\n",
    "\n",
    "            # compute cumsums\n",
    "            env_dc_1['cumsum'] = env_dc_1['it_power_total'].cumsum()\n",
    "            env_dc_2['cumsum'] = env_dc_2['it_power_total'].cumsum()\n",
    "            env_dc_2['cumsum_1'] = env_dc_2[env_dc_2['host_id'] == '0-0']['it_power_total'].cumsum()\n",
    "            env_dc_2['cumsum_2'] = env_dc_2[env_dc_2['host_id'] == '1-1']['it_power_total'].cumsum()\n",
    "\n",
    "            # set relative cumsums\n",
    "            env_dc_1['relative_cumsum'] = 100  \n",
    "            env_dc_2['relative_cumsum'] = 0\n",
    "            env_dc_2['relative_cumsum_1'] = 0\n",
    "            env_dc_2['relative_cumsum_2'] = 0\n",
    "            \n",
    "            # compute relative cumsums\n",
    "            for time in env_dc_1['timestamp'].unique():\n",
    "                env_dc_2.loc[env_dc_2['timestamp'] == time, 'relative_cumsum'] = \\\n",
    "                                  env_dc_2.loc[env_dc_2['timestamp'] == time, 'cumsum'] * 100 / env_dc_1.loc[env_dc_1['timestamp'] == time, 'cumsum'].values[0]\n",
    "                env_dc_2.loc[env_dc_2['timestamp'] == time, 'relative_cumsum_1'] = \\\n",
    "                                  env_dc_2.loc[env_dc_2['timestamp'] == time, 'cumsum_1'] * 100 / env_dc_1.loc[env_dc_1['timestamp'] == time, 'cumsum'].values[0]\n",
    "                env_dc_2.loc[env_dc_2['timestamp'] == time, 'relative_cumsum_2'] = \\\n",
    "                                  env_dc_2.loc[env_dc_2['timestamp'] == time, 'cumsum_2'] * 100 / env_dc_1.loc[env_dc_1['timestamp'] == time, 'cumsum'].values[0]\n",
    "            \n",
    "            # plot relative cumsums\n",
    "            ax1.plot(env_dc_1['timestamp'], env_dc_1['relative_cumsum'], 'o', ls='-', ms=10, color=colors2[0], label=f'{placement_policy} 1 DC', linewidth=2, markevery=0.1)\n",
    "            ax1.plot(env_dc_2['timestamp'].iloc[1::2], env_dc_2['relative_cumsum'].iloc[1::2], 's', ls='-', ms=10, color=colors2[1], label=f'{placement_policy} 2 DC sum', linewidth=2, markevery=0.15)\n",
    "            ax1.plot(env_dc_2[env_dc_2['host_id'] == '0-0']['timestamp'], env_dc_2[env_dc_2['host_id'] == '0-0']['relative_cumsum_1'], \n",
    "                    'v', ls='-', ms=10, color=colors2[2], label=f'{placement_policy} 2 DC, 1', linewidth=2, markevery=0.2)\n",
    "            ax1.plot(env_dc_2[env_dc_2['host_id'] == '1-1']['timestamp'], env_dc_2[env_dc_2['host_id'] == '1-1']['relative_cumsum_2'], \n",
    "                    '^', ls='-', ms=10, color=colors2[4], label=f'{placement_policy} 2 DC, 2', linewidth=2, markevery=0.25)\n",
    "            \n",
    "            draw_day_lines(env_dc_1, ax)\n",
    "            draw_day_lines(env_dc_1, ax1)\n",
    "\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            ax.set_ylim(0, top_limit)\n",
    "            ax.set_title('Lineplot')\n",
    "            ax.set_xlabel('Time [hours]')\n",
    "            ax.set_ylabel(f'Energy [{conversion_name}J]')\n",
    "\n",
    "            ax1.legend()\n",
    "            ax1.grid(True)\n",
    "            ax1.set_ylim(0)\n",
    "            ax1.set_title('Cumulative Energy Relative to 1 DC')\n",
    "            ax1.set_xlabel('Time [hours]')\n",
    "            ax1.set_ylabel(f'Percentage [%]')\n",
    "\n",
    "            \n",
    "            fig.suptitle('Power consumption comparison 1 DC vs 2 DCs for trace ' + dc_1)\n",
    "            plt.show()\n",
    "            \n",
    "            vs_graph_counter += 1\n",
    "        else:\n",
    "            print('trace too short: ', dc_1, ' ', len(env_dc_1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilization candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vs_graphs(utilization_candidates_fmp, theoretical_max, theoretical_min, MAX_NUM_OF_GRAPHS, 'FMP')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vs_graphs(duration_candidates_fmp, theoretical_max, theoretical_min, MAX_NUM_OF_GRAPHS, 'FMP')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilization candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vs_graphs(utilization_candidates_lah, theoretical_max, theoretical_min_dvfs, MAX_NUM_OF_GRAPHS, 'LAH')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vs_graphs(duration_candidates_lah, theoretical_max, theoretical_min_dvfs, MAX_NUM_OF_GRAPHS, 'LAH')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_res_10 = stats_dc1_df[stats_dc1_df['AvgResourceUsage'] >= 0.05].trace_name.values\n",
    "avg_res_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wawa = create_dataframe(path_ex1, 'environment.csv')\n",
    "wawa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wawa[wawa['trace_name'] == 'workflowhub_epigenomics_dataset-hep_grid5000_schema-0-2_epigenomics-hep-g5k-run001_parquet_tpp_fastest_machine_dcs_1']\n",
    "# wawa[wawa['trace_name'] == 'spec_trace-1_parquet_tpp_look_ahead_dcs_1'].plot(x='timestamp', y='it_power_total')\n",
    "\n",
    "# line1 = plt.plot([1, 3, 5, 2, 5, 3, 1], c='red', lw=5)\n",
    "# line2 = plt.plot([7, 2, 5, 7, 5, 2, 7], c='green', lw=5)\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(wawa[wawa['trace_name'] == 'spec_trace-1_parquet_tpp_fastest_machine_dcs_1'].timestamp, wawa[wawa['trace_name'] == 'spec_trace-1_parquet_tpp_fastest_machine_dcs_1'].it_power_total, c='red', alpha=0.5)\n",
    "# plt.plot(wawa[wawa['trace_name'] == 'spec_trace-1_parquet_tpp_look_ahead_dcs_1'].timestamp, wawa[wawa['trace_name'] == 'spec_trace-1_parquet_tpp_look_ahead_dcs_1'].it_power_total, c='blue', alpha=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(avg_res_10)):\n",
    "    if i % 2 == 1: continue\n",
    "    plt.plot(wawa[wawa['trace_name'] == avg_res_10[i]].timestamp, wawa[wawa['trace_name'] == avg_res_10[i]].it_power_total, alpha=0.5, c='red')\n",
    "    i += 1\n",
    "    plt.plot(wawa[wawa['trace_name'] == avg_res_10[i]].timestamp, wawa[wawa['trace_name'] == avg_res_10[i]].it_power_total, alpha=0.5, c='blue')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "376b25519dc368194a2df36897d97ac347cf957993780f20c077df31a3dcc548"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
